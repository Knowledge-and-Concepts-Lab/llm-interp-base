{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.hf_wrapper import HFWrapper\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "import torch\n",
    "from jaxtyping import Float, Int\n",
    "\n",
    "from torch import Tensor, nn\n",
    "from transformer_lens import ActivationCache, HookedTransformer, utils\n",
    "import einops\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import tqdm\n",
    "\n",
    "import transformer_lens.utils as utils\n",
    "import json\n",
    "import random\n",
    "import gc\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import einops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import requests\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "import csv\n",
    "from huggingface_hub import hf_hub_download\n",
    "from typing import List, Union, Optional, Callable\n",
    "from IPython.display import HTML, IFrame, clear_output, display\n",
    "from jaxtyping import Float, Int\n",
    "from IPython.display import IFrame\n",
    "from torch import Tensor, nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import ActivationCache, HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8513f055467c49099f27ce3f8a289d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = HFWrapper(\n",
    "    name=\"gemma-3-4b-it\",\n",
    "    path=\"google/gemma-3-4b-it\",\n",
    "    tl_support=False,\n",
    "    cache_dir=\"/mnt/dv/wid/projects3/Rogers-muri-human-ai/zstuddiford\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_test = model.get_logit_outs(\"Humpty Dumpty Fell Off The\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-9.1875e+00,  1.4609e+00,  3.2656e+00,  ..., -2.3315e-02,\n",
       "          -1.8311e-02, -1.4648e-02],\n",
       "         [-1.7875e+01, -1.6250e+01,  2.3340e-01,  ..., -2.6978e-02,\n",
       "          -3.4668e-02, -5.1270e-02],\n",
       "         [-9.7500e+00, -1.0938e+01,  1.7969e+00,  ..., -3.4180e-02,\n",
       "          -4.8096e-02, -3.0029e-02],\n",
       "         ...,\n",
       "         [-1.2875e+01, -6.5938e+00,  2.7344e+00,  ..., -8.0566e-02,\n",
       "          -1.0498e-01, -8.5449e-02],\n",
       "         [-1.1375e+01, -9.5625e+00, -7.0703e-01,  ..., -1.0352e-01,\n",
       "          -1.1914e-01, -1.0889e-01],\n",
       "         [-1.2125e+01,  4.2578e-01,  1.9375e+00,  ..., -1.2158e-01,\n",
       "          -1.3574e-01, -1.2891e-01]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Wall'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_top_next_token_str(str_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_alignment_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
